{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning & Neural Networks - Final Assigment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first steps are the basis for Part A-D. These steps involve the import of the necessary packages as well as the import of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "concrete_data = pd.read_csv('https://cocl.us/concrete_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 8) (1030,)\n",
      "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
      "       'Coarse Aggregate', 'Fine Aggregate', 'Age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = concrete_data.loc[:,:'Age']\n",
    "y = concrete_data['Strength']\n",
    "print(X.shape, y.shape)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function which builds and compiles the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for Part A, B, C\n",
    "def reg_model():\n",
    "    model = Sequential()\n",
    "    # hidden layer\n",
    "    model.add(Dense(10, activation = 'relu', input_shape = (8,)))\n",
    "    # output layer\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the training 50 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : training-mse 140.0875647726072 , testing-mse 162.8941641536607\n",
      "2 : training-mse 94.96946156537483 , testing-mse 98.47416174343203\n",
      "3 : training-mse 201.81160722327795 , testing-mse 224.97702975095945\n",
      "4 : training-mse 129.65946478982573 , testing-mse 162.90733819204593\n",
      "5 : training-mse 887.022772123678 , testing-mse 911.0965871836336\n",
      "6 : training-mse 106.82226956138663 , testing-mse 125.2479990245951\n",
      "7 : training-mse 939.0976908732717 , testing-mse 899.6469571319025\n",
      "8 : training-mse 121.30881660027576 , testing-mse 120.67944632416705\n",
      "9 : training-mse 112.88742018870276 , testing-mse 115.42485617335173\n",
      "10 : training-mse 1329.9391167120862 , testing-mse 1324.489942172244\n",
      "11 : training-mse 255.84359265035135 , testing-mse 327.00365226763944\n",
      "12 : training-mse 106.82772413404574 , testing-mse 115.03190949041903\n",
      "13 : training-mse 1071.0047346689169 , testing-mse 1233.3988730506308\n",
      "14 : training-mse 503.5723568814472 , testing-mse 537.6468978855753\n",
      "15 : training-mse 236.57082827246634 , testing-mse 240.18575396168038\n",
      "16 : training-mse 303.8582600713934 , testing-mse 312.17304715035783\n",
      "17 : training-mse 240.26862899208862 , testing-mse 245.07533899332358\n",
      "18 : training-mse 119.54697807618881 , testing-mse 131.74618935940344\n",
      "19 : training-mse 577.9373103762136 , testing-mse 559.7761218617311\n",
      "20 : training-mse 207.51834413314162 , testing-mse 225.4127547764096\n",
      "21 : training-mse 1951.8851028844488 , testing-mse 1774.5909494508135\n",
      "22 : training-mse 593.3236828088429 , testing-mse 480.9449831836295\n",
      "23 : training-mse 146.92320527646808 , testing-mse 142.95514894198325\n",
      "24 : training-mse 123.00134068884566 , testing-mse 135.07253899566686\n",
      "25 : training-mse 419.40144904741135 , testing-mse 427.97467888676255\n",
      "26 : training-mse 112.5417866488601 , testing-mse 118.2397419269852\n",
      "27 : training-mse 160.76794784905675 , testing-mse 178.40677488206694\n",
      "28 : training-mse 81.82601426080923 , testing-mse 82.98018049906966\n",
      "29 : training-mse 208.33791953416207 , testing-mse 254.60639004233988\n",
      "30 : training-mse 1034.8572452878489 , testing-mse 1254.5573321729782\n",
      "31 : training-mse 408.2933295642784 , testing-mse 378.89549728610285\n",
      "32 : training-mse 169.84198660460325 , testing-mse 179.0083093355705\n",
      "33 : training-mse 161.47287172484167 , testing-mse 140.56905137153677\n",
      "34 : training-mse 156.74486147051215 , testing-mse 158.2207029563116\n",
      "35 : training-mse 194.28125158725268 , testing-mse 228.62205621157014\n",
      "36 : training-mse 115.96145005563426 , testing-mse 130.75406878761163\n",
      "37 : training-mse 194.71728428855187 , testing-mse 189.1875029179346\n",
      "38 : training-mse 171.82332121151993 , testing-mse 200.37769629684175\n",
      "39 : training-mse 137.38112977936595 , testing-mse 150.84560365321522\n",
      "40 : training-mse 1798.32118239912 , testing-mse 1851.129779189516\n",
      "41 : training-mse 518.1217518884497 , testing-mse 508.8653521599464\n",
      "42 : training-mse 160.29565821209826 , testing-mse 179.50608433902397\n",
      "43 : training-mse 125.12880640122496 , testing-mse 138.56303456948308\n",
      "44 : training-mse 294.86552642949243 , testing-mse 345.3373049151689\n",
      "45 : training-mse 101.46064327626222 , testing-mse 109.57923013279084\n",
      "46 : training-mse 134.1454670306879 , testing-mse 166.45375800549115\n",
      "47 : training-mse 503.8913733367285 , testing-mse 588.719121857146\n",
      "48 : training-mse 245.90867858124838 , testing-mse 249.32829882851914\n",
      "49 : training-mse 196.82749219410297 , testing-mse 189.82903306060422\n",
      "50 : training-mse 394.05354340827085 , testing-mse 410.4508221920464\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors_test = np.zeros(50)\n",
    "mean_squared_errors_train = np.zeros(50)\n",
    "\n",
    "for i in range(50):\n",
    "    model_a = reg_model()\n",
    "    model_a.fit(X_train,y_train, #validation_split = 0,\n",
    "               epochs = 50, verbose = 0)\n",
    "    y_test_pred = model_a.predict(X_test)\n",
    "    mean_squared_errors_test[i] = mean_squared_error(y_test,y_test_pred)\n",
    "    mean_squared_errors_train[i] = model_a.history.history['loss'][-1]\n",
    "    print(str(i+1),': training-mse',mean_squared_errors_train[i],',',\n",
    "          'testing-mse',mean_squared_errors_test[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I compute the mean and standard deviation of the mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of mean squared errors:  388.35720095391775\n",
      "Standard Deviation of mean squared errors:  417.8121173508686\n"
     ]
    }
   ],
   "source": [
    "print('Mean of mean squared errors: ',np.mean(mean_squared_errors_test))\n",
    "print('Standard Deviation of mean squared errors: ', np.std(mean_squared_errors_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the predictor X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm = (X - X.mean())/(X.std())\n",
    "X_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = X_norm.iloc[X_train.index,]\n",
    "X_test_norm = X_norm.iloc[X_test.index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : training-mse 252.66142097293255 , testing-mse 272.0336326569612\n",
      "2 : training-mse 332.33239121774363 , testing-mse 357.88985585612994\n",
      "3 : training-mse 267.8942298624618 , testing-mse 296.65564398438516\n",
      "4 : training-mse 324.13814147864565 , testing-mse 360.39633583157575\n",
      "5 : training-mse 596.240748983481 , testing-mse 675.8999292575619\n",
      "6 : training-mse 261.34987618159323 , testing-mse 284.29554432098763\n",
      "7 : training-mse 462.2113705871836 , testing-mse 477.41029595029454\n",
      "8 : training-mse 241.23986333881436 , testing-mse 264.5588206211095\n",
      "9 : training-mse 204.76757268601415 , testing-mse 231.57869158964039\n",
      "10 : training-mse 298.5791843535996 , testing-mse 311.5571741649208\n",
      "11 : training-mse 376.5967083003749 , testing-mse 410.08310084313183\n",
      "12 : training-mse 517.6187242992047 , testing-mse 562.3584805232088\n",
      "13 : training-mse 253.73232723241375 , testing-mse 284.8170224839674\n",
      "14 : training-mse 308.197949413453 , testing-mse 327.02363833033\n",
      "15 : training-mse 418.3599384958635 , testing-mse 472.6570436320369\n",
      "16 : training-mse 660.2696594576895 , testing-mse 735.9022806590291\n",
      "17 : training-mse 294.98046240098927 , testing-mse 319.5464599575406\n",
      "18 : training-mse 295.28462919745795 , testing-mse 307.28324056721806\n",
      "19 : training-mse 268.25869621880014 , testing-mse 290.9806917061742\n",
      "20 : training-mse 262.0441610518838 , testing-mse 280.982041140454\n",
      "21 : training-mse 394.1197400985908 , testing-mse 417.4161120946718\n",
      "22 : training-mse 289.1191320115088 , testing-mse 299.8079254484008\n",
      "23 : training-mse 275.58441278507905 , testing-mse 286.94826375075337\n",
      "24 : training-mse 334.128776349241 , testing-mse 349.8527984488569\n",
      "25 : training-mse 604.9809031493124 , testing-mse 673.1106993185841\n",
      "26 : training-mse 276.5706731238081 , testing-mse 296.3784664928406\n",
      "27 : training-mse 288.5756326323574 , testing-mse 316.3930947197902\n",
      "28 : training-mse 454.5332687737707 , testing-mse 514.2882651749421\n",
      "29 : training-mse 391.6831305261789 , testing-mse 437.4349767161713\n",
      "30 : training-mse 327.82260999534066 , testing-mse 368.78244640890335\n",
      "31 : training-mse 309.67608909236577 , testing-mse 332.72351514580606\n",
      "32 : training-mse 362.24367600439655 , testing-mse 405.9176016117995\n",
      "33 : training-mse 307.3021046801182 , testing-mse 350.4541353193467\n",
      "34 : training-mse 306.8820408835656 , testing-mse 325.14029571984486\n",
      "35 : training-mse 295.87640156527664 , testing-mse 329.19682638483465\n",
      "36 : training-mse 362.35738335766837 , testing-mse 396.6643374775261\n",
      "37 : training-mse 434.6297175689147 , testing-mse 488.06275886564737\n",
      "38 : training-mse 421.379937583299 , testing-mse 449.75142752384124\n",
      "39 : training-mse 479.17776180272625 , testing-mse 495.19020934391733\n",
      "40 : training-mse 346.0358983223713 , testing-mse 368.7969719046431\n",
      "41 : training-mse 344.0301717263485 , testing-mse 368.3166674563895\n",
      "42 : training-mse 454.1239044147126 , testing-mse 495.191185533612\n",
      "43 : training-mse 361.0718689388111 , testing-mse 398.9508246092827\n",
      "44 : training-mse 301.01002106686406 , testing-mse 328.51336716465624\n",
      "45 : training-mse 367.83109788193616 , testing-mse 405.67266307213544\n",
      "46 : training-mse 296.46416137949274 , testing-mse 330.19099188565434\n",
      "47 : training-mse 225.75830526788423 , testing-mse 242.70848907136917\n",
      "48 : training-mse 284.38910424262906 , testing-mse 300.52923805435296\n",
      "49 : training-mse 405.6164794583261 , testing-mse 426.9522846861619\n",
      "50 : training-mse 277.80525582111164 , testing-mse 307.1216740186089\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors_test = np.zeros(50)\n",
    "mean_squared_errors_train = np.zeros(50)\n",
    "\n",
    "for i in range(50):\n",
    "    model_b = reg_model()\n",
    "    model_b.fit(X_train_norm,y_train, #validation_split = 0,\n",
    "               epochs = 50, verbose = 0)\n",
    "    y_test_pred = model_b.predict(X_test_norm)\n",
    "    mean_squared_errors_test[i] = mean_squared_error(y_test,y_test_pred)\n",
    "    mean_squared_errors_train[i] = model_b.history.history['loss'][-1]\n",
    "    print(str(i+1),': training-mse',mean_squared_errors_train[i],',',\n",
    "         'testing-mse',mean_squared_errors_test[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again I show the mean and standard deviation of the mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of mean squared errors:  380.60736875000003\n",
      "Standard Deviation of mean squared errors:  109.66138961619797\n"
     ]
    }
   ],
   "source": [
    "print('Mean of mean squared errors: ',np.mean(mean_squared_errors_test))\n",
    "print('Standard Deviation of mean squared errors: ', np.std(mean_squared_errors_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see the mean stays roughly the same, but the standard deviation is significantly smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Increase number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model 50 times with 100 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : training-mse 202.80315997035098 , testing-mse 230.6902624946909\n",
      "2 : training-mse 140.90757366291527 , testing-mse 162.67663355332954\n",
      "3 : training-mse 171.41011633588604 , testing-mse 194.6639585920373\n",
      "4 : training-mse 142.20705218057196 , testing-mse 166.6136064044422\n",
      "5 : training-mse 145.90666987065964 , testing-mse 169.1831264700522\n",
      "6 : training-mse 150.51090133603503 , testing-mse 178.86745184313972\n",
      "7 : training-mse 162.75229847943734 , testing-mse 179.86838866251372\n",
      "8 : training-mse 148.3583228842726 , testing-mse 172.8773423304024\n",
      "9 : training-mse 153.88661318711533 , testing-mse 175.04393306325287\n",
      "10 : training-mse 151.77850382007276 , testing-mse 173.223790434193\n",
      "11 : training-mse 145.1534066484639 , testing-mse 165.3639776130428\n",
      "12 : training-mse 174.7344817057066 , testing-mse 199.48276161015298\n",
      "13 : training-mse 171.8582119458922 , testing-mse 185.29100788399572\n",
      "14 : training-mse 147.084584144878 , testing-mse 167.44376736547687\n",
      "15 : training-mse 154.65591422198716 , testing-mse 182.26969937861372\n",
      "16 : training-mse 168.4758788596906 , testing-mse 195.53942455027394\n",
      "17 : training-mse 157.11288234165735 , testing-mse 183.13241866305077\n",
      "18 : training-mse 174.9798488325947 , testing-mse 198.2540181476893\n",
      "19 : training-mse 141.1423425237944 , testing-mse 164.08274999823175\n",
      "20 : training-mse 176.04217950447918 , testing-mse 202.97356246074577\n",
      "21 : training-mse 165.6624312486794 , testing-mse 189.73185716180276\n",
      "22 : training-mse 143.60805741097164 , testing-mse 163.02667387686418\n",
      "23 : training-mse 145.29111621449294 , testing-mse 173.0131797473403\n",
      "24 : training-mse 148.2173230810073 , testing-mse 173.54628793796277\n",
      "25 : training-mse 145.39211879523882 , testing-mse 165.38171504463114\n",
      "26 : training-mse 148.51622140490232 , testing-mse 168.75048957918995\n",
      "27 : training-mse 174.3830021872765 , testing-mse 189.41638193557586\n",
      "28 : training-mse 169.84549017918093 , testing-mse 200.67464783891674\n",
      "29 : training-mse 166.62563830837297 , testing-mse 184.0967158679601\n",
      "30 : training-mse 152.034865253676 , testing-mse 174.75764801111688\n",
      "31 : training-mse 193.92287592153775 , testing-mse 223.40824044773112\n",
      "32 : training-mse 144.87823686321963 , testing-mse 159.48072527606806\n",
      "33 : training-mse 150.48780611120216 , testing-mse 174.57552749830887\n",
      "34 : training-mse 157.47116850748472 , testing-mse 187.83673308368247\n",
      "35 : training-mse 166.56258994431832 , testing-mse 187.56690331529344\n",
      "36 : training-mse 136.10188549533797 , testing-mse 160.67843232907836\n",
      "37 : training-mse 146.9578909272129 , testing-mse 172.07004466142132\n",
      "38 : training-mse 163.43771901970598 , testing-mse 195.0205185826492\n",
      "39 : training-mse 140.32366422740498 , testing-mse 167.473315018834\n",
      "40 : training-mse 150.32738743542632 , testing-mse 175.2996433757891\n",
      "41 : training-mse 163.3152876601305 , testing-mse 180.9709600675249\n",
      "42 : training-mse 147.2796414993011 , testing-mse 172.98482705029102\n",
      "43 : training-mse 146.48607338152712 , testing-mse 169.03778880414762\n",
      "44 : training-mse 156.20143857577636 , testing-mse 180.9293723544634\n",
      "45 : training-mse 167.50899907719247 , testing-mse 195.85804480941988\n",
      "46 : training-mse 154.3859803812183 , testing-mse 182.6211213712655\n",
      "47 : training-mse 157.89040178994696 , testing-mse 178.3277046252629\n",
      "48 : training-mse 170.37387317757998 , testing-mse 194.68513648900475\n",
      "49 : training-mse 153.72222087717256 , testing-mse 174.27011334261857\n",
      "50 : training-mse 177.607490465479 , testing-mse 198.88103757494832\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors_test = np.zeros(50)\n",
    "mean_squared_errors_train = np.zeros(50)\n",
    "\n",
    "for i in range(50):\n",
    "    model_c = reg_model()\n",
    "    model_c.fit(X_train_norm,y_train, validation_split = 0,\n",
    "               epochs = 100, verbose = 0)\n",
    "    y_test_pred = model_c.predict(X_test_norm)\n",
    "    mean_squared_errors_test[i] = mean_squared_error(y_test,y_test_pred)\n",
    "    mean_squared_errors_train[i] = model_c.history.history['loss'][-1]\n",
    "    print(str(i+1),': training-mse',mean_squared_errors_train[i],',',\n",
    "         'testing-mse',mean_squared_errors_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again I print the mean and standard deviation of the mse's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of mean squared errors:  181.2382733719698\n",
      "Standard Deviation of mean squared errors:  15.021560027878989\n"
     ]
    }
   ],
   "source": [
    "print('Mean of mean squared errors: ',np.mean(mean_squared_errors_test))\n",
    "print('Standard Deviation of mean squared errors: ', np.std(mean_squared_errors_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both entities are smaller with 100 epochs than with 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D: Increase number of hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_model_d():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # hidden layer\n",
    "    model.add(Dense(10, activation = 'relu', input_shape = (8,)))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models with 3 hidden layers and 50 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : training-mse 113.41716891221299 , testing-mse 126.61619900966043\n",
      "2 : training-mse 103.41729847435812 , testing-mse 117.3582913682936\n",
      "3 : training-mse 52.58058227348592 , testing-mse 77.77012371134046\n",
      "4 : training-mse 77.29591542110364 , testing-mse 95.61717152314507\n",
      "5 : training-mse 74.68202663956006 , testing-mse 83.48849264603177\n",
      "6 : training-mse 102.73095234356376 , testing-mse 117.52906332366045\n",
      "7 : training-mse 111.19881634970147 , testing-mse 123.79365549290277\n",
      "8 : training-mse 94.22467286510705 , testing-mse 102.02463868028026\n",
      "9 : training-mse 83.93929306644011 , testing-mse 96.65111810224604\n",
      "10 : training-mse 48.27526385641958 , testing-mse 75.55951061514286\n",
      "11 : training-mse 46.702927291806624 , testing-mse 63.579271012251354\n",
      "12 : training-mse 41.00491225339172 , testing-mse 62.3044692655559\n",
      "13 : training-mse 60.61864770368134 , testing-mse 78.11773204553843\n",
      "14 : training-mse 56.61857126159245 , testing-mse 87.45910557972972\n",
      "15 : training-mse 77.82009394588815 , testing-mse 98.28551248597827\n",
      "16 : training-mse 43.011232563923535 , testing-mse 59.34420588627038\n",
      "17 : training-mse 96.8409793446365 , testing-mse 107.34409950931658\n",
      "18 : training-mse 58.73323063314705 , testing-mse 72.72515445274439\n",
      "19 : training-mse 91.85205732073102 , testing-mse 100.02940523446472\n",
      "20 : training-mse 48.87049135057341 , testing-mse 70.00916843453653\n",
      "21 : training-mse 69.76839983512889 , testing-mse 83.18018739261178\n",
      "22 : training-mse 35.58181588626602 , testing-mse 58.12377604809688\n",
      "23 : training-mse 105.80921601653925 , testing-mse 118.88152336483637\n",
      "24 : training-mse 95.57697941625334 , testing-mse 105.98300394868619\n",
      "25 : training-mse 59.4124973101358 , testing-mse 77.70430199380253\n",
      "26 : training-mse 72.03157137634024 , testing-mse 84.50762777175599\n",
      "27 : training-mse 78.57519580983917 , testing-mse 96.19538188144296\n",
      "28 : training-mse 76.83667963057054 , testing-mse 88.85903181201124\n",
      "29 : training-mse 97.93355123808249 , testing-mse 110.16276200906015\n",
      "30 : training-mse 44.58292554519378 , testing-mse 67.89725054346654\n",
      "31 : training-mse 78.25346027432467 , testing-mse 87.4763624714664\n",
      "32 : training-mse 104.24800963805221 , testing-mse 116.07701059490134\n",
      "33 : training-mse 57.90353101500195 , testing-mse 72.40778675752324\n",
      "34 : training-mse 58.18579980900483 , testing-mse 84.18966640383809\n",
      "35 : training-mse 99.06629170326518 , testing-mse 111.49433733907053\n",
      "36 : training-mse 108.91016196410963 , testing-mse 120.23008972500264\n",
      "37 : training-mse 60.50117816475327 , testing-mse 87.11076296621354\n",
      "38 : training-mse 50.33512878417969 , testing-mse 72.83809730151255\n",
      "39 : training-mse 67.70871025646278 , testing-mse 86.092280824911\n",
      "40 : training-mse 50.005831690667904 , testing-mse 70.5873717433262\n",
      "41 : training-mse 83.58361015372732 , testing-mse 102.201204266572\n",
      "42 : training-mse 96.93582377652024 , testing-mse 109.84736278423722\n",
      "43 : training-mse 97.53317775012054 , testing-mse 104.29558961741982\n",
      "44 : training-mse 112.68865771035712 , testing-mse 125.79622295210339\n",
      "45 : training-mse 40.31217501530535 , testing-mse 60.18770433787835\n",
      "46 : training-mse 101.01174279158721 , testing-mse 115.48258333195386\n",
      "47 : training-mse 47.69139536144664 , testing-mse 68.26538643826827\n",
      "48 : training-mse 76.06394207196493 , testing-mse 89.71681679158876\n",
      "49 : training-mse 92.38129925033421 , testing-mse 102.93463085357085\n",
      "50 : training-mse 103.98841347872963 , testing-mse 111.71114452161179\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors_test = np.zeros(50)\n",
    "mean_squared_errors_train = np.zeros(50)\n",
    "\n",
    "for i in range(50):\n",
    "    model_d = reg_model_d()\n",
    "    model_d.fit(X_train_norm,y_train, validation_split = 0,\n",
    "               epochs = 100, verbose = 0)\n",
    "    y_test_pred = model_d.predict(X_test_norm)\n",
    "    mean_squared_errors_test[i] = mean_squared_error(y_test,y_test_pred)\n",
    "    mean_squared_errors_train[i] = model_d.history.history['loss'][-1]\n",
    "    print(str(i+1),': training-mse',mean_squared_errors_train[i],',',\n",
    "         'testing-mse',mean_squared_errors_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again I print the mean and standard deviation of the mse's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of mean squared errors:  92.12087294335659\n",
      "Standard Deviation of mean squared errors:  19.57155532751725\n"
     ]
    }
   ],
   "source": [
    "print('Mean of mean squared errors: ',np.mean(mean_squared_errors_test))\n",
    "print('Standard Deviation of mean squared errors: ', np.std(mean_squared_errors_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situationthe mean and standard deviation of the mse's decrease with additional hidden layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
